{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入esim_torch\n",
      "导入Upsampler\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import esim_torch\n",
    "print(\"导入esim_torch\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/gwp/rpg_vid2e/upsampling')  # 替换为实际的路径，这个路径包含了upsampling目录\n",
    "from utils import Upsampler\n",
    "print(\"导入Upsampler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence number ./example/original/seq0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImageSequence: 100%|██████████| 8/8 [00:11<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本图片的shape： (9, 260, 346) 上采样后图片的shape： (65, 256, 320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "upsampler = Upsampler(input_dir=\"./example/original/seq0\", output_dir=\"./example/upsampled/seq0\")\n",
    "upsampler.upsample()\n",
    "\n",
    "# 读取原本图片\n",
    "image_files = sorted(glob.glob(\"./example/original/seq0/imgs/*.png\"))\n",
    "images = np.stack([cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in image_files])\n",
    "\n",
    "# 读取上采样后的图片\n",
    "image_files = sorted(glob.glob(\"./example/upsampled/seq0/imgs/*.png\"))\n",
    "usampled_images = np.stack([cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in image_files])\n",
    "\n",
    "print(\"原本图片的shape：\", images.shape, \"上采样后图片的shape：\", usampled_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence number ./esim_py/tests/data/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImageSequence: 100%|██████████| 160/160 [00:26<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n",
      "原本图片的shape： (161, 180, 240) 上采样后图片的shape： (321, 160, 224)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "upsampler = Upsampler(input_dir=\"./esim_py/tests/data/images\", output_dir=\"./esim_py/tests/data/upsampled/images\") #注意，图像序列要放在文件夹imgs下，且需要有fps.txt记录帧率\n",
    "upsampler.upsample()\n",
    "\n",
    "print(\"Loading images\")\n",
    "# 读取原本图片\n",
    "image_files = sorted(glob.glob(\"./esim_py/tests/data/images/images/*.png\"))\n",
    "images = np.stack([cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in image_files])\n",
    "\n",
    "# 读取上采样后的图片\n",
    "image_files = sorted(glob.glob(\"./esim_py/tests/data/upsampled/images/imgs/*.png\"))\n",
    "usampled_images = np.stack([cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in image_files])\n",
    "\n",
    "print(\"原本图片的shape：\", images.shape, \"上采样后图片的shape：\", usampled_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从原始图像中生成事件\n",
      "Generating events\n",
      "Total events: torch.Size([19630])\n"
     ]
    }
   ],
   "source": [
    "t_refractory_period_ns=1e9;#某个时间段内不会产生event\n",
    "esim = esim_torch.ESIM(contrast_threshold_neg=0.2, #定义负event的阈值\n",
    "                        contrast_threshold_pos=0.2, #定义正event的阈值\n",
    "                        refractory_period_ns=t_refractory_period_ns)  #refractory period in nanoseconds\n",
    "\n",
    "print(\"从原始图像中生成事件\")\n",
    "\n",
    "# 读取时间戳\n",
    "timestamps_s = np.genfromtxt(\"./esim_py/tests/data/images/timestamps.txt\")\n",
    "timestamps_ns = (timestamps_s * 1e9).astype(\"int64\")\n",
    "\n",
    "# 将图片转换为log scale\n",
    "log_images = np.log(images.astype(\"float32\") / 255 + 1e-4)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# torch tensor with type float32, shape T x H x W\n",
    "log_images = torch.from_numpy(log_images).to(device)\n",
    "# torch tensor with type int64,   shape T (已经转换为tensor)\n",
    "timestamps_ns = torch.from_numpy(timestamps_ns).to(device)\n",
    "\n",
    "# generate events with GPU support\n",
    "print(\"Generating events\")\n",
    "events = esim.forward(log_images, timestamps_ns)\n",
    "\n",
    "all_event = events\n",
    "print(f\"Total events: {all_event['x'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从上采样的图像中生成事件\n",
      "Generating events\n",
      "Total usampled events: torch.Size([18422])\n"
     ]
    }
   ],
   "source": [
    "print(\"从上采样的图像中生成事件\")\n",
    "\n",
    "esim_1 = esim_torch.ESIM(contrast_threshold_neg=0.2, #定义负event的阈值\n",
    "                        contrast_threshold_pos=0.2, #定义正event的阈值\n",
    "                        refractory_period_ns=t_refractory_period_ns)  #refractory period in nanoseconds\n",
    "\n",
    "# 读取时间戳\n",
    "upsample_timestamps_s = np.genfromtxt(\"./esim_py/tests/data/upsampled/timestamps.txt\")\n",
    "upsample_timestamps_ns = (upsample_timestamps_s * 1e9).astype(\"int64\")\n",
    "\n",
    "# 将图片转换为log scale\n",
    "usampled_log_images = np.log(usampled_images.astype(\"float32\") / 255 + 1e-4)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# torch tensor with type float32, shape T x H x W\n",
    "usampled_log_images = torch.from_numpy(usampled_log_images).to(device)\n",
    "# torch tensor with type int64,   shape T (已经转换为tensor)\n",
    "upsample_timestamps_ns = torch.from_numpy(upsample_timestamps_ns).to(device)\n",
    "\n",
    "# generate events with GPU support\n",
    "print(\"Generating events\")\n",
    "usampled_events = esim_1.forward(usampled_log_images, upsample_timestamps_ns)\n",
    "\n",
    "usampled_all_event = usampled_events\n",
    "print(f\"Total usampled events: {usampled_all_event['x'].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vid2e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
